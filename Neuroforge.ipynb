{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxpvYu7AdbBu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = \"\"\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/wizard_of_oz.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "chars = sorted(set(text))\n",
        "print(chars)\n",
        "print(len(text))\n",
        "print(text[:2000])\n",
        "vocab_size = len(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAtNgWxJdl_Q",
        "outputId": "9cfe6e36-210c-4bb9-d0ce-05472afe86ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\ufeff']\n",
            "232311\n",
            "ï»¿  DOROTHY AND THE WIZARD IN OZ\n",
            "\n",
            "  BY\n",
            "\n",
            "  L. FRANK BAUM\n",
            "\n",
            "  AUTHOR OF THE WIZARD OF OZ, THE LAND OF OZ, OZMA OF OZ, ETC.\n",
            "\n",
            "  ILLUSTRATED BY JOHN R. NEILL\n",
            "\n",
            "  BOOKS OF WONDER WILLIAM MORROW & CO., INC. NEW YORK\n",
            "\n",
            "\n",
            "  [Illustration]\n",
            "\n",
            "\n",
            "  COPYRIGHT 1908 BY L. FRANK BAUM\n",
            "\n",
            "  ALL RIGHTS RESERVED\n",
            "\n",
            "\n",
            "         *       *       *       *       *\n",
            "\n",
            "\n",
            "  [Illustration]\n",
            "\n",
            "\n",
            "  DEDICATED TO HARRIET A. B. NEAL.\n",
            "\n",
            "\n",
            "         *       *       *       *       *\n",
            "\n",
            "\n",
            "To My Readers\n",
            "\n",
            "\n",
            "It's no use; no use at all. The children won't let me stop telling tales\n",
            "of the Land of Oz. I know lots of other stories, and I hope to tell\n",
            "them, some time or another; but just now my loving tyrants won't allow\n",
            "me. They cry: \"Oz--Oz! more about Oz, Mr. Baum!\" and what can I do but\n",
            "obey their commands?\n",
            "\n",
            "This is Our Book--mine and the children's. For they have flooded me with\n",
            "thousands of suggestions in regard to it, and I have honestly tried to\n",
            "adopt as many of these suggestions as could be fitted into one story.\n",
            "\n",
            "After the wonderful success of \"Ozma of Oz\" it is evident that Dorothy\n",
            "has become a firm fixture in these Oz stories. The little ones all love\n",
            "Dorothy, and as one of my small friends aptly states: \"It isn't a real\n",
            "Oz story without her.\" So here she is again, as sweet and gentle and\n",
            "innocent as ever, I hope, and the heroine of another strange adventure.\n",
            "\n",
            "There were many requests from my little correspondents for \"more about\n",
            "the Wizard.\" It seems the jolly old fellow made hosts of friends in the\n",
            "first Oz book, in spite of the fact that he frankly acknowledged himself\n",
            "\"a humbug.\" The children had heard how he mounted into the sky in a\n",
            "balloon and they were all waiting for him to come down again. So what\n",
            "could I do but tell \"what happened to the Wizard afterward\"? You will\n",
            "find him in these pages, just the same humbug Wizard as before.\n",
            "\n",
            "There was one thing the children demanded which I found it impossible to\n",
            "do in this present book: they bade me introduce Toto, Dorothy's little\n",
            "black dog, who has many friends among my re\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string_to_int = { ch:i for i,ch in enumerate(chars) }\n",
        "int_to_string = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [string_to_int[c] for c in s]\n",
        "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
        "encoded_hello = encode('hello')\n",
        "decoded_hello = decode(encoded_hello)\n",
        "print(encoded_hello)\n",
        "print(decoded_hello)\n",
        "data = torch.tensor(encode(text), dtype = torch.long)\n",
        "print(data[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whn7Ld5ReIx8",
        "outputId": "99beb918-ad1f-4d15-f3f4-875bae56035c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[61, 58, 65, 65, 68]\n",
            "hello\n",
            "tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,\n",
            "         1, 47, 33, 50, 25, 42, 28,  1, 33, 38,  1, 39, 50,  0,  0,  1,  1, 26,\n",
            "        49,  0,  0,  1,  1, 36, 11,  1, 30, 42, 25, 38, 35,  1, 26, 25, 45, 37,\n",
            "         0,  0,  1,  1, 25, 45, 44, 32, 39, 42,  1, 39, 30,  1, 44, 32, 29,  1,\n",
            "        47, 33, 50, 25, 42, 28,  1, 39, 30,  1, 39, 50,  9,  1, 44, 32, 29,  1,\n",
            "        36, 25, 38, 28,  1, 39, 30,  1, 39, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 32\n",
        "batch_size = 16\n",
        "max_iters = 2000\n",
        "eval_interval = 500\n",
        "learning_rate = 3e-2\n",
        "eval_iters = 300\n",
        "n_embd = 384\n",
        "n_head = 2\n",
        "n_layer = 2\n",
        "dropout = 0.3"
      ],
      "metadata": {
        "id": "C38K8GyJeLfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.8*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "tAStIwVYeOry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size, ))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "KawPtWK9eR6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = get_batch('train')\n",
        "print('Inputs:')\n",
        "print(x)\n",
        "print('targets:')\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPAXeitweYkD",
        "outputId": "d2f8d654-0de7-4c5c-aafd-f5c3beba6769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            "tensor([[72, 72, 58, 57,  1, 72, 58, 75, 58, 71, 54, 65,  1, 66, 68, 71, 58,  0,\n",
            "         69, 71, 58, 73, 73, 78,  1, 56, 68, 73, 73, 54, 60, 58],\n",
            "        [71, 68, 73, 61, 78,  9,  1, 76, 61, 68,  1, 67, 68, 73, 62, 56, 58, 57,\n",
            "          1, 73, 61, 54, 73,  1, 73, 61, 58,  1, 55, 58, 54, 74],\n",
            "        [ 1, 72, 73, 54, 62, 71, 76, 54, 78,  1, 73, 61, 54, 73,  0, 76, 62, 65,\n",
            "         65,  1, 55, 71, 62, 67, 60,  1, 74, 72,  1, 68, 67,  1],\n",
            "        [ 1, 67, 68, 76,  1, 66, 78,  1, 65, 68, 75, 62, 67, 60,  1, 73, 78, 71,\n",
            "         54, 67, 73, 72,  1, 76, 68, 67,  5, 73,  1, 54, 65, 65],\n",
            "        [61, 58, 71, 72,  1, 73, 61, 58,  1, 65, 54, 72, 73,  1, 31, 54, 71, 60,\n",
            "         68, 78, 65, 58,  1, 72, 62, 65, 58, 67, 73, 65, 78,  1],\n",
            "        [ 1, 26, 74, 73,  1, 33,  1, 61, 54, 75, 58,  1, 55, 58, 58, 67,  1, 58,\n",
            "         77, 54, 66, 62, 67, 62, 67, 60,  1, 73, 61, 62, 72,  1],\n",
            "        [26, 74, 73,  1, 58, 75, 58, 67,  0, 73, 61, 54, 73,  1, 57, 62, 57,  1,\n",
            "         67, 68, 73,  1, 72, 54, 73, 62, 72, 59, 78,  1, 73, 61],\n",
            "        [58, 67,  1, 59, 62, 65, 65, 58, 57,  1, 74, 69,  1, 62, 67,  1, 73, 61,\n",
            "         58,  1, 76, 54, 65, 65,  1, 73, 61, 54, 73,  1, 72, 58],\n",
            "        [ 9,  1, 33, 38, 27, 11,  1, 38, 29, 47,  1, 49, 39, 42, 35,  0,  0,  0,\n",
            "          1,  1, 51, 33, 65, 65, 74, 72, 73, 71, 54, 73, 62, 68],\n",
            "        [67, 73, 58, 71, 58, 72, 73, 11,  1, 44, 61, 58, 78,  0, 72, 54, 76,  1,\n",
            "         54,  1, 66, 54, 72, 72,  1, 68, 59,  1, 73, 68, 74, 60],\n",
            "        [56, 68, 67, 59, 74, 72, 58, 57, 11,  1, 26, 74, 73,  1, 28, 68, 71, 68,\n",
            "         73, 61, 78,  9,  1, 72, 58, 58, 62, 67, 60,  0, 61, 62],\n",
            "        [ 0,  0, 44, 61, 58, 78,  1, 66, 68, 74, 67, 73, 58, 57,  1, 62, 67, 73,\n",
            "         68,  1, 73, 61, 58,  1, 55, 74, 60, 60, 78,  9,  1, 28],\n",
            "        [62, 59,  1, 78, 68, 74,  1, 60, 58, 73,  1, 62, 67, 73, 68,  1, 73, 71,\n",
            "         68, 74, 55, 65, 58,  1, 57, 68, 67,  5, 73,  1, 55, 65],\n",
            "        [60,  1, 72, 56, 54, 71, 58, 57,  1, 54,  1, 55, 62, 73, 11,  1, 39, 67,\n",
            "         56, 58,  1, 54,  0, 65, 62, 73, 73, 65, 58,  1, 59, 62],\n",
            "        [65,  1, 68, 74, 73,  1, 73, 68,  1, 60, 58, 73,  1, 78, 68, 74, 11,  1,\n",
            "         33, 59,  1, 78, 68, 74,  0, 56, 61, 68, 68, 72, 58,  1],\n",
            "        [ 1, 65, 54, 67, 57, 11,  0,  0, 33, 67, 72, 62, 57, 58,  1, 73, 61, 58,\n",
            "          1, 54, 71, 56, 61, 76, 54, 78,  1, 76, 58, 71, 58,  1]])\n",
            "targets:\n",
            "tensor([[72, 58, 57,  1, 72, 58, 75, 58, 71, 54, 65,  1, 66, 68, 71, 58,  0, 69,\n",
            "         71, 58, 73, 73, 78,  1, 56, 68, 73, 73, 54, 60, 58, 72],\n",
            "        [68, 73, 61, 78,  9,  1, 76, 61, 68,  1, 67, 68, 73, 62, 56, 58, 57,  1,\n",
            "         73, 61, 54, 73,  1, 73, 61, 58,  1, 55, 58, 54, 74, 73],\n",
            "        [72, 73, 54, 62, 71, 76, 54, 78,  1, 73, 61, 54, 73,  0, 76, 62, 65, 65,\n",
            "          1, 55, 71, 62, 67, 60,  1, 74, 72,  1, 68, 67,  1, 73],\n",
            "        [67, 68, 76,  1, 66, 78,  1, 65, 68, 75, 62, 67, 60,  1, 73, 78, 71, 54,\n",
            "         67, 73, 72,  1, 76, 68, 67,  5, 73,  1, 54, 65, 65, 68],\n",
            "        [58, 71, 72,  1, 73, 61, 58,  1, 65, 54, 72, 73,  1, 31, 54, 71, 60, 68,\n",
            "         78, 65, 58,  1, 72, 62, 65, 58, 67, 73, 65, 78,  1, 57],\n",
            "        [26, 74, 73,  1, 33,  1, 61, 54, 75, 58,  1, 55, 58, 58, 67,  1, 58, 77,\n",
            "         54, 66, 62, 67, 62, 67, 60,  1, 73, 61, 62, 72,  1, 73],\n",
            "        [74, 73,  1, 58, 75, 58, 67,  0, 73, 61, 54, 73,  1, 57, 62, 57,  1, 67,\n",
            "         68, 73,  1, 72, 54, 73, 62, 72, 59, 78,  1, 73, 61, 58],\n",
            "        [67,  1, 59, 62, 65, 65, 58, 57,  1, 74, 69,  1, 62, 67,  1, 73, 61, 58,\n",
            "          1, 76, 54, 65, 65,  1, 73, 61, 54, 73,  1, 72, 58, 69],\n",
            "        [ 1, 33, 38, 27, 11,  1, 38, 29, 47,  1, 49, 39, 42, 35,  0,  0,  0,  1,\n",
            "          1, 51, 33, 65, 65, 74, 72, 73, 71, 54, 73, 62, 68, 67],\n",
            "        [73, 58, 71, 58, 72, 73, 11,  1, 44, 61, 58, 78,  0, 72, 54, 76,  1, 54,\n",
            "          1, 66, 54, 72, 72,  1, 68, 59,  1, 73, 68, 74, 60, 61],\n",
            "        [68, 67, 59, 74, 72, 58, 57, 11,  1, 26, 74, 73,  1, 28, 68, 71, 68, 73,\n",
            "         61, 78,  9,  1, 72, 58, 58, 62, 67, 60,  0, 61, 62, 72],\n",
            "        [ 0, 44, 61, 58, 78,  1, 66, 68, 74, 67, 73, 58, 57,  1, 62, 67, 73, 68,\n",
            "          1, 73, 61, 58,  1, 55, 74, 60, 60, 78,  9,  1, 28, 68],\n",
            "        [59,  1, 78, 68, 74,  1, 60, 58, 73,  1, 62, 67, 73, 68,  1, 73, 71, 68,\n",
            "         74, 55, 65, 58,  1, 57, 68, 67,  5, 73,  1, 55, 65, 54],\n",
            "        [ 1, 72, 56, 54, 71, 58, 57,  1, 54,  1, 55, 62, 73, 11,  1, 39, 67, 56,\n",
            "         58,  1, 54,  0, 65, 62, 73, 73, 65, 58,  1, 59, 62, 72],\n",
            "        [ 1, 68, 74, 73,  1, 73, 68,  1, 60, 58, 73,  1, 78, 68, 74, 11,  1, 33,\n",
            "         59,  1, 78, 68, 74,  0, 56, 61, 68, 68, 72, 58,  1, 73],\n",
            "        [65, 54, 67, 57, 11,  0,  0, 33, 67, 72, 62, 57, 58,  1, 73, 61, 58,  1,\n",
            "         54, 71, 56, 61, 76, 54, 78,  1, 76, 58, 71, 58,  1, 72]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print('when input is', context, 'target is', target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtXzyMBUeZBa",
        "outputId": "801a4920-5c43-49d9-a9a1-edbd5a941f36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([80]) target is tensor(1)\n",
            "when input is tensor([80,  1]) target is tensor(1)\n",
            "when input is tensor([80,  1,  1]) target is tensor(28)\n",
            "when input is tensor([80,  1,  1, 28]) target is tensor(39)\n",
            "when input is tensor([80,  1,  1, 28, 39]) target is tensor(42)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42]) target is tensor(39)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39]) target is tensor(44)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44]) target is tensor(32)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32]) target is tensor(49)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49]) target is tensor(1)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1]) target is tensor(25)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25]) target is tensor(38)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38]) target is tensor(28)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28]) target is tensor(1)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1]) target is tensor(44)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44]) target is tensor(32)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32]) target is tensor(29)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29]) target is tensor(1)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,\n",
            "         1]) target is tensor(47)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,\n",
            "         1, 47]) target is tensor(33)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,\n",
            "         1, 47, 33]) target is tensor(50)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,\n",
            "         1, 47, 33, 50]) target is tensor(25)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,\n",
            "         1, 47, 33, 50, 25]) target is tensor(42)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,\n",
            "         1, 47, 33, 50, 25, 42]) target is tensor(28)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,\n",
            "         1, 47, 33, 50, 25, 42, 28]) target is tensor(1)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,\n",
            "         1, 47, 33, 50, 25, 42, 28,  1]) target is tensor(33)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,\n",
            "         1, 47, 33, 50, 25, 42, 28,  1, 33]) target is tensor(38)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,\n",
            "         1, 47, 33, 50, 25, 42, 28,  1, 33, 38]) target is tensor(1)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,\n",
            "         1, 47, 33, 50, 25, 42, 28,  1, 33, 38,  1]) target is tensor(39)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,\n",
            "         1, 47, 33, 50, 25, 42, 28,  1, 33, 38,  1, 39]) target is tensor(50)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,\n",
            "         1, 47, 33, 50, 25, 42, 28,  1, 33, 38,  1, 39, 50]) target is tensor(0)\n",
            "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,\n",
            "         1, 47, 33, 50, 25, 42, 28,  1, 33, 38,  1, 39, 50,  0]) target is tensor(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input of size (batch, time-step, channels)\n",
        "        # output of size (batch, time-step, head size)\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,hs)\n",
        "        q = self.query(x) # (B,T,hs)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,hs)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
        "        return out\n",
        "\n",
        "# [1, 0, 0]\n",
        "# [1, 0.6, 0]\n",
        "# [1, 0.6, 0.4]\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1) # (B, T, F) -> (B, T, [h1, h1, h1, h1, h2, h2, h2, h2, h3, h3, h3, h3])\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.sa(x)\n",
        "        x = self.ln1(x + y)\n",
        "        y = self.ffwd(x)\n",
        "        x = self.ln2(x + y)\n",
        "        return x\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, index, targets=None):\n",
        "        B, T = index.shape\n",
        "\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(index) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, index, max_new_tokens):\n",
        "        # index is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            index_cond = index[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self.forward(index_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
        "        return index\n",
        "\n",
        "model = GPTLanguageModel(vocab_size)\n",
        "# print('loading model parameters...')\n",
        "# with open('model-01.pkl', 'rb') as f:\n",
        "# model = pickle.load(f)\n",
        "# print('loaded successfully!')"
      ],
      "metadata": {
        "id": "klOATVTSecFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "train_loss_history = []\n",
        "val_loss_history = []\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_iters == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
        "        train_loss_history.append(losses['train'])\n",
        "        val_loss_history.append(losses['val'])\n",
        "    xb, yb = get_batch('train')\n",
        "    logits, loss = model.forward(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Plot the loss history after training\n",
        "plt.plot(train_loss_history, label='Train Loss')\n",
        "plt.plot(val_loss_history, label='Validation Loss')\n",
        "plt.xlabel('Evaluation Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss History')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "M1RPW47YefRI",
        "outputId": "7373b5c0-4009-49be-8a97-59848b549e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 0, train loss: 4.501, val loss: 4.496\n",
            "step: 300, train loss: 3.191, val loss: 3.214\n",
            "step: 600, train loss: 3.153, val loss: 3.164\n",
            "step: 900, train loss: 3.162, val loss: 3.162\n",
            "step: 1200, train loss: 3.143, val loss: 3.154\n",
            "step: 1500, train loss: 3.144, val loss: 3.150\n",
            "step: 1800, train loss: 3.146, val loss: 3.160\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = torch.zeros((1,1), dtype=torch.long)\n",
        "generated_chars = decode(model.generate(context, max_new_tokens=500)[0].tolist())\n",
        "print(generated_chars)"
      ],
      "metadata": {
        "id": "DuRlIouketXo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6523ca0-53f1-4613-dd05-ff9b708572d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ieado a vot,er\n",
            "s  d xeeWi  Tcao\n",
            "iwmrpdE its.l'i tTd;rsrrft;k \"ts nsh r, eaeet a\" soste\"t ut aO  oNDas\n",
            "fcctsgahEer e oeoe ncardaoa e CnZpI  oiag \n",
            "dsW.ImHv\"t cnezoattuod.aa -oirn   .ku sep edar o b h .llhgo ass tp .arteotneawhu.i psiaa r\n",
            "tt\n",
            "oagiuhh lwfoNt lZp  cho h wodpWsf\"itimnPO tliimot  s rri \n",
            "htg eocoet\"-rfrieetorteno taoo eitr gtitssryvoyGdu  oiedxneotu  epDengho jgc\n",
            "wttadsleeyIhlwf n\"\n",
            "smn, arrtfhpco  \n",
            "D\"bnlnwG\n",
            "ie itk seelgetlerttie\n",
            "pfn d phcnen    ggrawr  wspl ia\"shbp Lnrs sd o \"l e   eicnd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flag = 1\n",
        "while flag != 0:\n",
        "    prompt = input(\"Prompt:\\n\")\n",
        "    context = torch.tensor(encode(prompt), dtype=torch.long)\n",
        "    generated_chars = decode(model.generate(context.unsqueeze(0), max_new_tokens=150)[0].tolist())\n",
        "    print(f'Completion:\\n{generated_chars}')"
      ],
      "metadata": {
        "id": "2xyAm5U6exFn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "outputId": "9843c8c7-ee28-4067-b27d-80d98c6de9d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:\n",
            "Hello\n",
            "Completion:\n",
            "Hellooets r uA,\n",
            " na i \" ck\n",
            " vbohhnt  cg\n",
            "n i etJnatdiw bpeahrohWe iap  rwwis l od-ueIntO\"tgj z* ietrp ce eh  hr wetW w s agts\"fg  h luaeyvgt   \"uth yew enah\n",
            "Prompt:\n",
            "baby\n",
            "Completion:\n",
            "babytaiem,ie e.l?ea,creanm\n",
            "grh\n",
            " c.eeheep netr a  t JOt\n",
            "vv  traOeaogatmr tceheeit ov  atigucun eeaae   v ecvlgletlskattl is  ltfnot g \n",
            "eetlgtdt \n",
            " kDsyhsfsb\n",
            "Prompt:\n",
            "kantap padega\n",
            "Completion:\n",
            "kantap padegaidPct\"uwceunie neoh.'aCa\n",
            "Heldvcbi .w i muhwtehniurYi renw vs\n",
            "dgpfde\"redabtTie L\"ee oh\"tCtcnrhAut Hr H\"oyalsiehn\"t\n",
            "aglIdoseadttxt eH oarenie i,dhend\"sw\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-9d2526875283>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mflag\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prompt:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgenerated_chars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "import gradio as gr\n",
        "import torch\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, index, targets=None):\n",
        "        B, T = index.shape\n",
        "\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(index) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, index, max_new_tokens):\n",
        "        # index is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            index_cond = index[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self.forward(index_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
        "        return index\n",
        "\n",
        "from gradio import Textbox\n",
        "\n",
        "def predict(prompt):\n",
        "    context = torch.tensor(encode(prompt), dtype=torch.long)\n",
        "    generated_chars = decode(model.generate(context.unsqueeze(0), max_new_tokens=150)[0].tolist())\n",
        "    return generated_chars\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict,\n",
        "    # Directly use Textbox\n",
        "    inputs=Textbox(lines=2, placeholder=\"Enter your prompt here...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Wizard of Oz LLM\",\n",
        "    description=\"This LLM is trained on the Wizard of Oz text.\",\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "id": "kxAuRKzbNGpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-WF8yzhJWEbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Hyperparameters (adjust as necessary)\n",
        "n_embd = 256        # Embedding dimension\n",
        "block_size = 128    # Maximum number of tokens in the context\n",
        "n_layer = 4         # Number of transformer blocks\n",
        "n_head = 8          # Number of attention heads\n",
        "dropout = 0.12      # Dropout probability\n",
        "vocab_size = len(chars)  # Size of the vocabulary (adjust as per your tokenizer)\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\"One head of self-attention\"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x)  # (B, T, head_size)\n",
        "        q = self.query(x)  # (B, T, head_size)\n",
        "        wei = q @ k.transpose(-2, -1) * (k.shape[-1] ** -0.5)  # (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))  # Mask\n",
        "        wei = F.softmax(wei, dim=-1)  # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        v = self.value(x)  # (B, T, head_size)\n",
        "        out = wei @ v  # (B, T, head_size)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"Multiple heads of self-attention in parallel\"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)  # Concatenate heads\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\"A simple linear layer followed by a non-linearity\"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\"Transformer block: communication followed by computation\"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.sa(x)\n",
        "        x = self.ln1(x + y)\n",
        "        y = self.ffwd(x)\n",
        "        x = self.ln2(x + y)\n",
        "        return x\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, index, targets=None):\n",
        "        B, T = index.shape\n",
        "        tok_emb = self.token_embedding_table(index)  # (B, T, C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=index.device))  # Device agnostic positional embedding\n",
        "        x = tok_emb + pos_emb  # (B, T, C)\n",
        "        x = self.blocks(x)  # (B, T, C)\n",
        "        x = self.ln_f(x)  # (B, T, C)\n",
        "        logits = self.lm_head(x)  # (B, T, vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B * T, C)\n",
        "            targets = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def top_k_sampling(self, logits, k=10):\n",
        "        values, indices = torch.topk(logits, k=k)\n",
        "        top_probs = F.softmax(values, dim=-1)\n",
        "        return torch.multinomial(top_probs, num_samples=1)\n",
        "\n",
        "    def generate(self, index, max_new_tokens, temperature=1.0, top_k=10):\n",
        "        for _ in range(max_new_tokens):\n",
        "            index_cond = index[:, -block_size:]  # Crop to block size\n",
        "            logits, _ = self.forward(index_cond)\n",
        "            logits = logits[:, -1, :]  # Focus on last time step\n",
        "            logits = logits / temperature  # Apply temperature\n",
        "            index_next = self.top_k_sampling(logits, k=top_k)  # Top-k sampling\n",
        "            index = torch.cat((index, index_next), dim=1)  # Append to sequence\n",
        "        return index\n",
        "\n",
        "# Model instantiation\n",
        "model = GPTLanguageModel(vocab_size)\n",
        "\n",
        "# Example usage\n",
        "index = torch.tensor([[1, 2, 3]])  # Dummy tokenized input\n",
        "max_new_tokens = 50  # Number of tokens to generate\n",
        "generated_text = model.generate(index, max_new_tokens=max_new_tokens, temperature=1.0, top_k=10)\n",
        "\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "id": "69zSvBCdYgHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "train_loss_history = []\n",
        "val_loss_history = []\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_iters == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
        "        train_loss_history.append(losses['train'])\n",
        "        val_loss_history.append(losses['val'])\n",
        "    xb, yb = get_batch('train')\n",
        "    logits, loss = model.forward(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Plot the loss history after training\n",
        "plt.plot(train_loss_history, label='Train Loss')\n",
        "plt.plot(val_loss_history, label='Validation Loss')\n",
        "plt.xlabel('Evaluation Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss History')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YtMPY7ZuYidz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, index, targets=None):\n",
        "        B, T = index.shape\n",
        "        tok_emb = self.token_embedding_table(index)  # (B, T, C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=index.device))  # Device agnostic positional embedding\n",
        "        x = tok_emb + pos_emb  # (B, T, C)\n",
        "        x = self.blocks(x)  # (B, T, C)\n",
        "        x = self.ln_f(x)  # (B, T, C)\n",
        "        logits = self.lm_head(x)  # (B, T, vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B * T, C)\n",
        "            targets = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def top_k_sampling(self, logits, k=10):\n",
        "        values, indices = torch.topk(logits, k=k)\n",
        "        top_probs = F.softmax(values, dim=-1)\n",
        "        return torch.multinomial(top_probs, num_samples=1)\n",
        "\n",
        "    def generate(self, index, max_new_tokens, temperature=1.0, top_k=10):\n",
        "        for _ in range(max_new_tokens):\n",
        "            index_cond = index[:, -block_size:]  # Crop to block size\n",
        "            logits, _ = self.forward(index_cond)\n",
        "            logits = logits[:, -1, :]  # Focus on last time step\n",
        "            logits = logits / temperature  # Apply temperature\n",
        "            index_next = self.top_k_sampling(logits, k=top_k)  # Top-k sampling\n",
        "            index = torch.cat((index, index_next), dim=1)  # Append to sequence\n",
        "        return index\n",
        "\n",
        "from gradio import Textbox\n",
        "\n",
        "def predict(prompt):\n",
        "    context = torch.tensor(encode(prompt), dtype=torch.long)\n",
        "    generated_chars = decode(model.generate(context.unsqueeze(0), max_new_tokens=150)[0].tolist())\n",
        "    return generated_chars\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict,\n",
        "    # Directly use Textbox\n",
        "    inputs=Textbox(lines=2, placeholder=\"Enter your prompt here...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"NeuroForge\",\n",
        "    description=\"This is an Encoder-decoder LLM\",\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "id": "ssdBkJTfYoi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hmTTR9GYczEl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}